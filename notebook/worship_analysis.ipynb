{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unlocking Church Growth: Data Insights from the National Congregations Study\n",
    "# Worship Service Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "In this segment of the analysis we specifically explore the features associated to the Worship Service of the congregation and how they may impact an attendance change. The features included are:<br>\n",
    " - Services: The number of services per week\n",
    " - Lenght: length of service in minutes\n",
    " - Sermon: was a sermon involved in the worship service?\n",
    " - Sermon Time: length of the sermon in minutes\n",
    " - Podium: did the speaker come down off the altar, podium, chancel, or stage during hte sermon?\n",
    " - Unique Speakers: how many unique speakers were there?\n",
    " - Greetings: Was time allocated for greetings, handshaking, etc. during the service?\n",
    " - Kids: was a part of the service specifically for children?\n",
    " - Teens: were any speaking, singing, or performing parts specifically for teens in the service?\n",
    " - Robe: did the clergy leader wear a robe?\n",
    " - Applause: was there applause during any point of the service?\n",
    " - Laughing: was laughing invoked during the service?\n",
    " - Bulletin: was a program, bulletin, or other written order of service distributed?\n",
    " - Streamed: was the service broadcast or streamed live?\n",
    " - Smartphone: were people offered the opportunity to use their smartphones to participate in some way?\n",
    " - Congregational Reading: did hte congregation speak, read, or recite something together at any point?\n",
    " - Offering: was a monetary offering collected during the service?\n",
    " - Social Time: how long did people mingle informally before and after the service in minutes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from scipy.stats import spearmanr, pearsonr, chi2_contingency, fisher_exact\n",
    "from scipy.stats.contingency import relative_risk\n",
    "from scipy.stats.contingency import odds_ratio\n",
    "from scipy.stats import f_oneway  # Inferential Analysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE # Rancom Forest oversampling\n",
    "import itertools\n",
    "\n",
    "\n",
    "# Import DictionaryCollection class from Dictionaries.py\n",
    "    # Download the file from GitHub\n",
    "url = 'https://raw.githubusercontent.com/NRSchaaf/unlocking-church-growth/main/notebook/dictionaries.py'\n",
    "response = requests.get(url)\n",
    "\n",
    "    # Save the file locally\n",
    "with open('dictionaries.py', 'wb') as file:\n",
    "    file.write(response.content)\n",
    "from dictionaries import dictionaryCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "url = 'https://raw.githubusercontent.com/NRSchaaf/unlocking-church-growth/main/dataset/dataset.csv'\n",
    "data = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DictionaryCollection instance\n",
    "dict_collection = dictionaryCollection()\n",
    "\n",
    "# Replace numerical values column with string values from dictionaries\n",
    "data = dict_collection.replace_numeric_values(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seaborn_style(font_family, background_color, grid_color, text_color):\n",
    "    sns.set_style({\n",
    "        \"axes.facecolor\": background_color,\n",
    "        \"figure.facecolor\": background_color,\n",
    "\n",
    "        \"grid.color\": grid_color,\n",
    "        \"axes.edgecolor\": grid_color,\n",
    "        \"axes.grid\": True,\n",
    "        \"axes.axisbelow\": True,\n",
    "        \n",
    "        \"axes.labelcolor\": text_color,\n",
    "        \"text.color\": text_color,\n",
    "        \"font.family\": font_family,\n",
    "        \"xtick.color\": text_color,\n",
    "        \"ytick.color\": text_color,\n",
    "\n",
    "        \"xtick.bottom\": False,\n",
    "        \"xtick.top\": False,\n",
    "        \"ytick.left\": False,\n",
    "        \"ytick.right\": False,\n",
    "\n",
    "        \"axes.spines.left\": False,\n",
    "        \"axes.spines.bottom\": True,\n",
    "        \"axes.spines.right\": False,\n",
    "        \"axes.spines.top\": False,\n",
    "    }\n",
    ")\n",
    "\n",
    "background_color = \"#006064\"\n",
    "grid_color = \"#cccccc\"\n",
    "bar_color = \"#009688\"\n",
    "text_color = \"#ffffff\"\n",
    "font_family = \"Arial\"\n",
    "\n",
    "set_seaborn_style(font_family, background_color, grid_color, text_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new features based on conditions\n",
    "data['change_category'] = data['CHANGE'].apply(\n",
    "    lambda x: \"Increase\" if \"Increased\" in str(x) else (\"Decrease\" if \"Decreased\" in str(x) else (\"Same\" if \"Same\" in str(x) else \"Same\"))\n",
    ")\n",
    "\n",
    "# Change column data types\n",
    "data['DENOM'] = data['DENOM'].astype('category')\n",
    "data['change_category'] = data['change_category'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select specific features\n",
    "selected_columns = ['DENOM', 'NUMSERV1', 'LENGTH', 'SERMON', 'SERMTIME', 'SPKRDWN', 'NUMSPOKE', 'GREET', 'KIDTIME', 'TEENPART', 'ROBE', 'APPLAUSE', 'LAUGH', 'PROGRAM', 'OVERHEAD', 'STREAMED', 'SMTPHONE', 'CONGREAD', 'OFFERING', 'SOCLTIME', 'change_category']\n",
    "df_worship = data[selected_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop DENOM\n",
    "df_worship.drop(['DENOM'], axis=1, inplace=True)\n",
    "\n",
    "# One-Hot Encoding\n",
    "categorical_columns = df_worship.select_dtypes(include=['category']).columns.tolist()\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_features = encoder.fit_transform(df_worship[categorical_columns])\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(categorical_columns))\n",
    "df_worship_encoded = pd.concat([df_worship, encoded_df], axis=1)\n",
    "df_worship_encoded = df_worship_encoded.drop(categorical_columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic exploration\n",
    "df_worship.info()\n",
    "df_worship.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "Correlation Analysis: Use correlation matrices to identify relationships between congregational offerings and attendance.<br>\n",
    "Visualization: Create visualizations such as histograms, box plots, scatter plots, and heatmaps to explore patterns and trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform correlation analysis\n",
    "correlation_matrix = df_worship_encoded.corr()\n",
    "\n",
    "plt.figure(figsize=(40,20))  # Adjust the figure size if needed\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", vmin=-1, vmax=1)\n",
    "\n",
    "# Add plot title and show plot\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify columns of interest\n",
    "columns_of_interest = ['SERMON', 'SPKRDWN', 'GREET', 'KIDTIME', 'TEENPART', 'ROBE', 'APPLAUSE', 'LAUGH', 'PROGRAM', 'OVERHEAD', 'STREAMED', 'SMTPHONE', 'CONGREAD', 'OFFERING']\n",
    "\n",
    "# Count True values for each column\n",
    "counts = {col: df_worship_encoded[col].sum() for col in columns_of_interest}\n",
    "\n",
    "# Sort counts in descending order\n",
    "sorted_counts = dict(sorted(counts.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# Plot counts for each column as multiple bars in one graph\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Create the bar plot with sorted counts\n",
    "plt.bar(sorted_counts.keys(), sorted_counts.values(), color='skyblue')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Count of True Values')\n",
    "plt.title('Count of True Values in Selected Columns (Descending Order)')\n",
    "\n",
    "# Show plot\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of True and False values in the 'APPLAUSE' column\n",
    "applause_counts = df_worship_encoded['APPLAUSE'].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(\"Counts of boolean values in 'APPLAUSE':\")\n",
    "print(applause_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferential Analysis\n",
    "Hypothesis Testing: Conduct hypothesis tests (e.g., t-tests, ANOVA) to determine if there are statistically significant differences in attendance based on different offerings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inferential Analysis\n",
    "\n",
    "# Select specific features and drop rows with missing target data\n",
    "df_facilities_inferential = data[['BLDGTYPE', 'VIEWBLDG', 'REMODEL', 'HOMESCHL', 'HAVESCHL', 'USEBLDG', 'PERMPURP', 'change_category']]\n",
    "\n",
    "# Drop rows with missing target data\n",
    "df_facilities_inferential = df_facilities_inferential.dropna(subset=['change_category'])\n",
    "\n",
    "# Convert facility type columns to categorical\n",
    "facilities_types = ['VIEWBLDG', 'REMODEL', 'HOMESCHL', 'HAVESCHL', 'USEBLDG']\n",
    "for col in facilities_types:\n",
    "    df_facilities_inferential[col] = df_facilities_inferential[col].astype('category')\n",
    "\n",
    "# Function to perform Chi-Square test\n",
    "def perform_chi2_test(df, feature):\n",
    "    contingency_table = pd.crosstab(df[feature], df['change_category'])\n",
    "    chi2_stat, p_val, dof, expected = chi2_contingency(contingency_table)\n",
    "    return chi2_stat, p_val\n",
    "\n",
    "# Perform Chi-Square test for each feature\n",
    "chi2_results = {feature: perform_chi2_test(df_facilities_inferential, feature) for feature in facilities_types}\n",
    "\n",
    "# Display Chi-Square results\n",
    "for feature, (chi2_stat, p_val) in chi2_results.items():\n",
    "    print(f\"Chi-Square test for {feature}: Chi2-statistic = {chi2_stat:.4f}, p-value = {p_val:.4e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot relationship\n",
    "def plot_relationship(df, feature):\n",
    "    contingency_table = pd.crosstab(df[feature], df['change_category'])\n",
    "    contingency_table.plot(kind='bar', stacked=True, colormap='viridis')\n",
    "    plt.title(f'Relationship between {feature} and change_category')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend(title='Change Category')\n",
    "    plt.show()\n",
    "\n",
    "# Plot relationships\n",
    "for feature in facilities_types:\n",
    "    plot_relationship(df_facilities_inferential, feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Analysis\n",
    "Linear Regression: Model the relationship between congregational size (dependent variable) and offerings (independent variables) using linear regression.<br>\n",
    "Logistic Regression: If the outcome is categorical (e.g., increased attendance vs. no increase), use logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine NaN value counts in each column\n",
    "nan_counts = df_facilities.isnull().sum()\n",
    "print(\"NaN value counts in each column:\")\n",
    "print(nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "# Select specific columns and drop NaN values\n",
    "df_facilities_logit = df_facilities[['REMODEL', 'HOMESCHL', 'HAVESCHL', 'change_category']].dropna()\n",
    "\n",
    "# One-Hot Encoding for the target variable\n",
    "df_facilities_logit['change_category'] = df_facilities_logit['change_category'].astype('category')\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_target = encoder.fit_transform(df_facilities_logit[['change_category']])\n",
    "encoded_target_df = pd.DataFrame(encoded_target, columns=encoder.get_feature_names_out(['change_category']))\n",
    "\n",
    "# Merge encoded target with the main dataframe and drop the original target column\n",
    "df_facilities_logit = pd.concat([df_facilities_logit.reset_index(drop=True), encoded_target_df], axis=1)\n",
    "df_facilities_logit.drop(['change_category'], axis=1, inplace=True)\n",
    "\n",
    "# Encode the target variable for logistic regression\n",
    "# Assuming 'change_category_Increase' is the column for the positive class\n",
    "target = df_facilities_logit['change_category_Increase']\n",
    "df_facilities_logit.drop(['change_category_Increase', 'change_category_Decrease', 'change_category_Same'], axis=1, inplace=True)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_facilities_logit, target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set results\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Optional: Feature importance\n",
    "feature_importance = pd.Series(model.coef_[0], index=X_train.columns).sort_values(ascending=False)\n",
    "print(\"Feature Importance:\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Analysis\n",
    "Multiple Regression: Extend linear regression to include multiple independent variables to account for the effect of various factors simultaneously.<br>\n",
    "Principal Component Analysis (PCA): Reduce dimensionality and identify key factors contributing to attendance changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Analysis\n",
    "Trend Analysis: Examine how congregational size and offerings have changed over time.<br>\n",
    "Seasonality: Identify seasonal patterns in attendance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Analysis\n",
    "Machine Learning Models: Implement machine learning models (e.g., decision trees, random forests, gradient boosting) to predict attendance based on congregational offerings.<br>\n",
    "Model Evaluation: Use cross-validation and performance metrics (e.g., RMSE, AUC) to assess model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "# Apply SMOTE to the training data to handle class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict the test set results\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Optional: Feature importance\n",
    "feature_importance = pd.Series(model.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "print(\"Feature Importance:\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature combinations to test\n",
    "input_combinations = pd.DataFrame({\n",
    "    'REMODEL': [1, 0, 1, 0, 1, 0, 0, 0],  # Test various combinations of 'yes' (1) and 'no' (0)\n",
    "    'HOMESCHL': [1, 1, 0, 0, 1, 1, 0, 0],\n",
    "    'HAVESCHL': [1, 1, 1, 1, 0, 0, 0, 0],\n",
    "    # Add other features if needed; here we assume they are all zero\n",
    "})\n",
    "\n",
    "# Ensure all columns are present in the input combinations\n",
    "for col in X_train.columns:\n",
    "    if col not in input_combinations.columns:\n",
    "        input_combinations[col] = 0\n",
    "\n",
    "# Predict probabilities using the Random Forest model\n",
    "predicted_probs = model.predict_proba(input_combinations)\n",
    "\n",
    "# Convert predictions to a DataFrame for visualization\n",
    "# The `model.classes_` should be ['decrease', 'increase', 'same'] or in a similar order\n",
    "predicted_df = pd.DataFrame(predicted_probs, columns=model.classes_)\n",
    "predicted_df['Combination'] = ['Remodel=Yes, Homeschl=Yes, Haveschl=Yes', \n",
    "                               'Remodel=No, Homeschl=Yes, Haveschl=Yes',\n",
    "                               'Remodel=Yes, Homeschl=No, Haveschl=Yes',\n",
    "                               'Remodel=No, Homeschl=No, Haveschl=Yes',\n",
    "                               'Remodel=Yes, Homeschl=Yes, Haveschl=No',\n",
    "                               'Remodel=No, Homeschl=Yes, Haveschl=No',\n",
    "                               'Remodel=Yes, Homeschl=No, Haveschl=No',\n",
    "                               'Remodel=No, Homeschl=No, Haveschl=No']\n",
    "\n",
    "# Melt the DataFrame for easier plotting with seaborn\n",
    "melted_df = pd.melt(predicted_df, id_vars='Combination', var_name='Change Category', value_name='Probability')\n",
    "\n",
    "# Plotting the probabilities\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=melted_df, x='Combination', y='Probability', hue='Change Category', palette='viridis')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Predicted Probabilities for Change Category for Various Feature Combinations')\n",
    "plt.tight_layout()\n",
    "plt.legend(title='Change Category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal Analysis\n",
    "Causal Inference: Use methods like propensity score matching or instrumental variables to identify causal relationships between offerings and attendance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations\n",
    "Actionable Insights: Provide recommendations based on the analysis, highlighting which factors most significantly influence attendance.<br>\n",
    "Scenario Analysis: Simulate different scenarios to predict the impact of changes in offerings on attendance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
